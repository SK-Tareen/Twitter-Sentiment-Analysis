{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Zero -- Shot Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_1\n"
     ]
    }
   ],
   "source": [
    "#CardiffNLP fine tuned roBERTa based one shot\n",
    "#We used this model to look at hor different prompts effect the results\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    prompt = f\"Is this tweet positive, neutral or negative:\\n\\nTweet: \\\"{tweet}\\\"\\n\\nSentiment:\"\n",
    "    result = sentiment_pipeline(prompt)\n",
    "    return result[0]['label']\n",
    "\n",
    "tweet = \"They are all like this\"\n",
    "sentiment = analyze_sentiment(tweet)\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_2\n"
     ]
    }
   ],
   "source": [
    "#CardiffNLP fine tuned roBERTa based one shot\n",
    "#We used this model to look at hor different prompts effect the results\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    prompt = f\"This looks positive. Is this tweet positive, neutral or negative:\\n\\nTweet: \\\"{tweet}\\\"\\n\\nSentiment:\"\n",
    "    result = sentiment_pipeline(prompt)\n",
    "    return result[0]['label']\n",
    "\n",
    "tweet = \"They are all like this\"\n",
    "sentiment = analyze_sentiment(tweet)\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0\n"
     ]
    }
   ],
   "source": [
    "#CardiffNLP fine tuned roBERTa based one shot\n",
    "#We used this model to look at hor different prompts effect the results\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    prompt = f\"This looked negative. Is this tweet positive, neutral or negative:\\n\\nTweet: \\\"{tweet}\\\"\\n\\nSentiment:\"\n",
    "    result = sentiment_pipeline(prompt)\n",
    "    return result[0]['label']\n",
    "\n",
    "tweet = \"They are all like this\"\n",
    "sentiment = analyze_sentiment(tweet)\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: 'I went home' -> Sentiment: LABEL_1, Score: 0.73\n",
      "Tweet: 'I love life' -> Sentiment: LABEL_2, Score: 0.98\n",
      "Tweet: 'I hate life' -> Sentiment: LABEL_0, Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "#Roberta Based model\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "tweets = [\n",
    "    \"I went home\",\n",
    "    \"I love life\",\n",
    "    \"I hate life\"\n",
    "]\n",
    "\n",
    "results = sentiment_pipeline(tweets)\n",
    "\n",
    "for tweet, result in zip(tweets, results):\n",
    "    print(f\"Tweet: '{tweet}' -> Sentiment: {result['label']}, Score: {result['score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: NEGATIVE, Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "#Default usage of DistilBert\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "tweet = \"I hate life\"\n",
    "sentiment = sentiment_pipeline(tweet)\n",
    "\n",
    "print(f\"Sentiment: {sentiment[0]['label']}, Score: {sentiment[0]['score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "#Distilbert based One shot\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    result = sentiment_pipeline(tweet)\n",
    "    return result[0]['label']\n",
    "\n",
    "tweet = \"I will wait for the new features\"\n",
    "sentiment = analyze_sentiment(tweet)\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task: Classify the sentiment of the text as either positive or negative.\n",
      "\n",
      "Text: \"I'm so not happy with the service!\"\n",
      "Sentiment: \"I'm so not happy with the service!\"\n",
      "\n",
      "Task: Create a\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "zero_shot_prompt = \"\"\"\n",
    "Task: Classify the sentiment of the text as either positive or negative.\n",
    "\n",
    "Text: \"I'm so not happy with the service!\"\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "inputs = tokenizer(zero_shot_prompt, return_tensors=\"pt\", padding=True)\n",
    "inputs[\"attention_mask\"] = inputs[\"input_ids\"] != tokenizer.pad_token_id\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"], \n",
    "    attention_mask=inputs[\"attention_mask\"], \n",
    "    max_length=50, \n",
    "    num_return_sequences=1, \n",
    "    temperature=0.7, \n",
    "    top_p=0.9,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "#Bart Large mnli \n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    candidate_labels = [\"positive\", \"negative\", \"neutral\"]\n",
    "    \n",
    "    result = classifier(tweet, candidate_labels)\n",
    "    sentiment = result['labels'][0]  \n",
    "    return sentiment\n",
    "\n",
    "tweet = \"I will go home\"\n",
    "sentiment = analyze_sentiment(tweet)\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot Result: negative\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-large\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "zero_shot_prompt = \"This looks positive. Classify the sentiment of the following text as positive or not:\\nText: 'I'm so not happy with the service!'\"\n",
    "inputs = tokenizer(zero_shot_prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=50)\n",
    "\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Zero-Shot Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Few - Shot Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Result: positive\n"
     ]
    }
   ],
   "source": [
    "# Define the few-shot prompt with examples\n",
    "few_shot_prompt = \"\"\"\n",
    "Classify the sentiment of the following text as positive or negative keeping in mind sarcasm as a factor.\n",
    "\n",
    "Example 1:\n",
    "Text: \"I love the new update; it works perfectly!\"\n",
    "Sentiment: positive\n",
    "\n",
    "Example 2:\n",
    "Text: \"I'm disappointed with the app; it keeps crashing.\"\n",
    "Sentiment: negative\n",
    "\n",
    "Example 3:\n",
    "Text: \"The features are good, but it could be improved.\"\n",
    "Sentiment: neutral\n",
    "\n",
    "Example 4:\n",
    "Text: \"I am so glad i have to spend all my money here. This is so not a drag\"\n",
    "Sentiment: negative\n",
    "\n",
    "Now, classify the sentiment of this text:\n",
    "Text: \"They told me to be here. I so love being here and spending my precious time on this project\"\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=50)\n",
    "\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Few-Shot Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0\n"
     ]
    }
   ],
   "source": [
    "#roBERTa Based\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    prompt = (\n",
    "        \"which  sentiment of each of the following tweets as positive or negative:\\n\\n\"\n",
    "        \"Example 1: 'I love this new phone; it's amazing!' -> Sentiment: positive\\n\"\n",
    "        \"Example 2: 'The weather is terrible today.' -> Sentiment: negative\\n\"\n",
    "        \"Example 3: 'Can't believe how fast it arrived, great service!' -> Sentiment: positive\\n\"\n",
    "        f\"Example 4: '{tweet}' -> Sentiment:\"\n",
    "    )\n",
    "    result = sentiment_pipeline(prompt)\n",
    "    return result[0]['label']\n",
    "\n",
    "tweet = \"I hate this app\"\n",
    "sentiment = analyze_sentiment(tweet)\n",
    "\n",
    "print(f\"Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
